{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19daa496-d252-446c-a702-57b9c7ca381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, classification_report, confusion_matrix\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a04cfcf-b447-4ce9-bae6-51e0276ea1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88d9d815-df2d-4836-bc71-3756128426bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with shape: (10000, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disaster_id</th>\n",
       "      <th>disaster_type</th>\n",
       "      <th>location</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>date</th>\n",
       "      <th>fatalities</th>\n",
       "      <th>economic_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Wildfire</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>6.267393</td>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "      <td>9706</td>\n",
       "      <td>6.509790e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Hurricane</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>6.649358</td>\n",
       "      <td>2024-01-01 01:00:00</td>\n",
       "      <td>2233</td>\n",
       "      <td>5.538357e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>China</td>\n",
       "      <td>9.724366</td>\n",
       "      <td>2024-01-01 02:00:00</td>\n",
       "      <td>478</td>\n",
       "      <td>6.910998e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Flood</td>\n",
       "      <td>India</td>\n",
       "      <td>1.702505</td>\n",
       "      <td>2024-01-01 03:00:00</td>\n",
       "      <td>2867</td>\n",
       "      <td>8.474880e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Flood</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>7.917748</td>\n",
       "      <td>2024-01-01 04:00:00</td>\n",
       "      <td>776</td>\n",
       "      <td>6.449297e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disaster_id disaster_type   location  magnitude                 date  \\\n",
       "0            1      Wildfire     Brazil   6.267393  2024-01-01 00:00:00   \n",
       "1            2     Hurricane  Indonesia   6.649358  2024-01-01 01:00:00   \n",
       "2            3       Tornado      China   9.724366  2024-01-01 02:00:00   \n",
       "3            4         Flood      India   1.702505  2024-01-01 03:00:00   \n",
       "4            5         Flood     Brazil   7.917748  2024-01-01 04:00:00   \n",
       "\n",
       "   fatalities  economic_loss  \n",
       "0        9706   6.509790e+08  \n",
       "1        2233   5.538357e+08  \n",
       "2         478   6.910998e+07  \n",
       "3        2867   8.474880e+08  \n",
       "4         776   6.449297e+08  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = r\"C:\\Users\\Lenovo\\natural_disasters_2024.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# clean column names\n",
    "df.columns = (df.columns.str.strip()\n",
    "                           .str.lower()\n",
    "                           .str.replace(r'[^0-9a-zA-Z]+', '_', regex=True)\n",
    "                           .str.strip('_'))\n",
    "\n",
    "print(\"Loaded dataset with shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e99cc77-4fed-4238-a666-b6d79171053a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disaster_id</th>\n",
       "      <th>disaster_type</th>\n",
       "      <th>location</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>date</th>\n",
       "      <th>fatalities</th>\n",
       "      <th>economic_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Wildfire</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>6.267393</td>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "      <td>9706</td>\n",
       "      <td>6.509790e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Hurricane</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>6.649358</td>\n",
       "      <td>2024-01-01 01:00:00</td>\n",
       "      <td>2233</td>\n",
       "      <td>5.538357e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>China</td>\n",
       "      <td>9.724366</td>\n",
       "      <td>2024-01-01 02:00:00</td>\n",
       "      <td>478</td>\n",
       "      <td>6.910998e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Flood</td>\n",
       "      <td>India</td>\n",
       "      <td>1.702505</td>\n",
       "      <td>2024-01-01 03:00:00</td>\n",
       "      <td>2867</td>\n",
       "      <td>8.474880e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Flood</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>7.917748</td>\n",
       "      <td>2024-01-01 04:00:00</td>\n",
       "      <td>776</td>\n",
       "      <td>6.449297e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disaster_id disaster_type   location  magnitude                 date  \\\n",
       "0            1      Wildfire     Brazil   6.267393  2024-01-01 00:00:00   \n",
       "1            2     Hurricane  Indonesia   6.649358  2024-01-01 01:00:00   \n",
       "2            3       Tornado      China   9.724366  2024-01-01 02:00:00   \n",
       "3            4         Flood      India   1.702505  2024-01-01 03:00:00   \n",
       "4            5         Flood     Brazil   7.917748  2024-01-01 04:00:00   \n",
       "\n",
       "   fatalities  economic_loss  \n",
       "0        9706   6.509790e+08  \n",
       "1        2233   5.538357e+08  \n",
       "2         478   6.910998e+07  \n",
       "3        2867   8.474880e+08  \n",
       "4         776   6.449297e+08  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types:\n",
      " disaster_id        int64\n",
      "disaster_type     object\n",
      "location          object\n",
      "magnitude        float64\n",
      "date              object\n",
      "fatalities         int64\n",
      "economic_loss    float64\n",
      "dtype: object\n",
      "\n",
      "Missing values per column:\n",
      " disaster_id      0\n",
      "disaster_type    0\n",
      "location         0\n",
      "magnitude        0\n",
      "date             0\n",
      "fatalities       0\n",
      "economic_loss    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Preview, dtypes, and missing count\n",
    "display(df.head(5))\n",
    "print(\"\\nData types:\\n\", df.dtypes)\n",
    "print(\"\\nMissing values per column:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15917edb-59d4-40b7-911f-e2ef5a06e93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>disaster_id</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5000.5</td>\n",
       "      <td>2886.89568</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2500.75</td>\n",
       "      <td>5000.5</td>\n",
       "      <td>7500.25</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disaster_type</th>\n",
       "      <td>10000</td>\n",
       "      <td>5</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>2036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>10000</td>\n",
       "      <td>6</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>1743</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>magnitude</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.559173</td>\n",
       "      <td>2.619304</td>\n",
       "      <td>1.000656</td>\n",
       "      <td>3.263217</td>\n",
       "      <td>5.589578</td>\n",
       "      <td>7.829268</td>\n",
       "      <td>9.999671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>2025-02-19 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fatalities</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4984.9289</td>\n",
       "      <td>2900.114029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2481.75</td>\n",
       "      <td>4947.0</td>\n",
       "      <td>7511.25</td>\n",
       "      <td>9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economic_loss</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504975202.468649</td>\n",
       "      <td>286132461.919491</td>\n",
       "      <td>1036596.729037</td>\n",
       "      <td>263635212.274709</td>\n",
       "      <td>507840727.349273</td>\n",
       "      <td>752725573.776602</td>\n",
       "      <td>999852819.13456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count unique                  top  freq              mean  \\\n",
       "disaster_id    10000.0    NaN                  NaN   NaN            5000.5   \n",
       "disaster_type    10000      5           Earthquake  2036               NaN   \n",
       "location         10000      6               Brazil  1743               NaN   \n",
       "magnitude      10000.0    NaN                  NaN   NaN          5.559173   \n",
       "date             10000  10000  2025-02-19 23:00:00     1               NaN   \n",
       "fatalities     10000.0    NaN                  NaN   NaN         4984.9289   \n",
       "economic_loss  10000.0    NaN                  NaN   NaN  504975202.468649   \n",
       "\n",
       "                            std             min               25%  \\\n",
       "disaster_id          2886.89568             1.0           2500.75   \n",
       "disaster_type               NaN             NaN               NaN   \n",
       "location                    NaN             NaN               NaN   \n",
       "magnitude              2.619304        1.000656          3.263217   \n",
       "date                        NaN             NaN               NaN   \n",
       "fatalities          2900.114029             0.0           2481.75   \n",
       "economic_loss  286132461.919491  1036596.729037  263635212.274709   \n",
       "\n",
       "                            50%               75%              max  \n",
       "disaster_id              5000.5           7500.25          10000.0  \n",
       "disaster_type               NaN               NaN              NaN  \n",
       "location                    NaN               NaN              NaN  \n",
       "magnitude              5.589578          7.829268         9.999671  \n",
       "date                        NaN               NaN              NaN  \n",
       "fatalities               4947.0           7511.25           9999.0  \n",
       "economic_loss  507840727.349273  752725573.776602  999852819.13456  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with 'risk' in name: []\n",
      "No risk_score-like column found; continue with your numeric features.\n"
     ]
    }
   ],
   "source": [
    "# Descriptive stats\n",
    "display(df.describe(include='all').T)\n",
    "\n",
    "# If there is a risk score-like column, try to locate it\n",
    "risk_cols = [c for c in df.columns if 'risk' in c]\n",
    "print(\"Columns with 'risk' in name:\", risk_cols)\n",
    "\n",
    "# Plot distribution if 'risk_score' exists (or first matched)\n",
    "if 'risk_score' in df.columns:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    df['risk_score'].hist(bins=30)\n",
    "    plt.title('risk_score distribution')\n",
    "    plt.xlabel('risk_score')\n",
    "    plt.ylabel('count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "elif len(risk_cols)>0:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    df[risk_cols[0]].hist(bins=30)\n",
    "    plt.title(f'{risk_cols[0]} distribution')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No risk_score-like column found; continue with your numeric features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65c15d8d-12d2-4544-9d76-36e7f82dbcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No change: either 'risk_score' missing or 'risk_level' already exists.\n"
     ]
    }
   ],
   "source": [
    "# If a continuous risk_score exists but no categorical risk_level, create risk_level\n",
    "if 'risk_score' in df.columns and 'risk_level' not in df.columns:\n",
    "    df['risk_level'] = pd.cut(df['risk_score'], bins=[-np.inf,33,66,np.inf], labels=['Low','Medium','High'])\n",
    "    print(\"Created 'risk_level' from 'risk_score' with bins Low/Medium/High.\")\n",
    "else:\n",
    "    print(\"No change: either 'risk_score' missing or 'risk_level' already exists.\")\n",
    "    \n",
    "# Quick counts\n",
    "if 'risk_level' in df.columns:\n",
    "    print(\"\\nRisk level distribution:\")\n",
    "    print(df['risk_level'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ad5e912-dd4f-4568-ab71-00af85bd1022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-detected feature columns: ['magnitude', 'fatalities', 'economic_loss']\n",
      "Detected date column: date\n"
     ]
    }
   ],
   "source": [
    "# Helper to find first matching column given candidate substrings\n",
    "def find_col(df, candidate_list):\n",
    "    for cand in candidate_list:\n",
    "        for col in df.columns:\n",
    "            if cand in col:\n",
    "                return col\n",
    "    return None\n",
    "\n",
    "# Candidate names to search for (will adapt to your file)\n",
    "col_mag = find_col(df, ['magnitude','mag','intensity'])\n",
    "col_fatal = find_col(df, ['fatalitie','death','fatal'])\n",
    "col_econ = find_col(df, ['economic','economic_loss','loss','economic_loss'])\n",
    "col_pop = find_col(df, ['population','population_density','pop_density'])\n",
    "col_prec = find_col(df, ['precip','rain','precipitation'])\n",
    "col_temp = find_col(df, ['temp','temperature','anomaly'])\n",
    "col_lat = find_col(df, ['lat','latitude'])\n",
    "col_lon = find_col(df, ['lon','longitude'])\n",
    "col_date = find_col(df, ['date','year','timestamp'])\n",
    "\n",
    "# Build features list from found columns\n",
    "features = [c for c in [col_mag, col_fatal, col_econ, col_pop, col_prec, col_temp, col_lat, col_lon] if c is not None]\n",
    "\n",
    "print(\"Auto-detected feature columns:\", features)\n",
    "if col_date:\n",
    "    print(\"Detected date column:\", col_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd8d22c0-5914-450f-872e-b750e8f51523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed missing numeric values with median. Any NaNs left: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>magnitude</th>\n",
       "      <th>fatalities</th>\n",
       "      <th>economic_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.267393</td>\n",
       "      <td>9706.0</td>\n",
       "      <td>6.509790e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.649358</td>\n",
       "      <td>2233.0</td>\n",
       "      <td>5.538357e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.724366</td>\n",
       "      <td>478.0</td>\n",
       "      <td>6.910998e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.702505</td>\n",
       "      <td>2867.0</td>\n",
       "      <td>8.474880e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.917748</td>\n",
       "      <td>776.0</td>\n",
       "      <td>6.449297e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   magnitude  fatalities  economic_loss\n",
       "0   6.267393      9706.0   6.509790e+08\n",
       "1   6.649358      2233.0   5.538357e+08\n",
       "2   9.724366       478.0   6.910998e+07\n",
       "3   1.702505      2867.0   8.474880e+08\n",
       "4   7.917748       776.0   6.449297e+08"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select target columns (prefer continuous risk_score)\n",
    "target_reg = 'risk_score' if 'risk_score' in df.columns else None\n",
    "target_clf = 'risk_level' if 'risk_level' in df.columns else None\n",
    "\n",
    "# Safety check: if no features detected, ask user to manually specify\n",
    "if len(features)==0:\n",
    "    raise ValueError(\"No numeric feature columns auto-detected. Edit the features list manually using actual column names from df.columns.\")\n",
    "\n",
    "# Subset X and targets\n",
    "X = df[features].copy()\n",
    "y_reg = df[target_reg] if target_reg else None\n",
    "y_clf = df[target_clf] if target_clf else None\n",
    "\n",
    "# Impute numeric columns using median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns, index=X.index)\n",
    "print(\"Imputed missing numeric values with median. Any NaNs left:\", X_imputed.isnull().sum().sum())\n",
    "\n",
    "# Optionally scale later when training\n",
    "X_imputed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a555923-e3dc-4eac-b2cd-bb62d566d37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common split settings\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "def make_split_and_scale(X_df, y_series):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_df, y_series, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train_s = scaler.transform(X_train)\n",
    "    X_test_s  = scaler.transform(X_test)\n",
    "    return X_train, X_test, X_train_s, X_test_s, y_train, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20395640-c361-4b85-bd50-372a135c9839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No continuous 'risk_score' target found — skipping regression.\n"
     ]
    }
   ],
   "source": [
    "# Run regression if target available\n",
    "if y_reg is not None:\n",
    "    X_train, X_test, X_train_s, X_test_s, y_train, y_test, scaler_reg = make_split_and_scale(X_imputed, y_reg)\n",
    "    rfr = RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    rfr.fit(X_train_s, y_train)\n",
    "    y_pred = rfr.predict(X_test_s)\n",
    "\n",
    "    # Metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(\"Regression results → MAE: {:.3f}, RMSE: {:.3f}, R2: {:.3f}\".format(mae, rmse, r2))\n",
    "\n",
    "    # Feature importances\n",
    "    fi = pd.Series(rfr.feature_importances_, index=X_imputed.columns).sort_values(ascending=False)\n",
    "    print(\"\\nFeature importances:\\n\", fi)\n",
    "\n",
    "    # Plot actual vs predicted\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "    mn = min(y_test.min(), y_pred.min()); mx = max(y_test.max(), y_pred.max())\n",
    "    plt.plot([mn,mx],[mn,mx], 'r--', lw=1)\n",
    "    plt.xlabel(\"Actual\")\n",
    "    plt.ylabel(\"Predicted\")\n",
    "    plt.title(\"Actual vs Predicted (Regression)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"plots/actual_vs_pred_regression.png\", dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "    # Residuals histogram\n",
    "    plt.figure(figsize=(6,4))\n",
    "    (y_test - y_pred).hist(bins=30)\n",
    "    plt.title(\"Regression residuals (y_test - y_pred)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"plots/residuals_regression.png\", dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "    # Save model & scaler\n",
    "    joblib.dump(rfr, \"models/rfr_risk_score.joblib\")\n",
    "    joblib.dump(scaler_reg, \"models/scaler_reg.joblib\")\n",
    "    print(\"Saved RandomForestRegressor and scaler in /models.\")\n",
    "else:\n",
    "    print(\"No continuous 'risk_score' target found — skipping regression.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09c7f205-ba30-4669-a787-75966881ef1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No categorical 'risk_level' target found — skipping classification.\n"
     ]
    }
   ],
   "source": [
    "# Run classification if categorical risk_level exists\n",
    "if y_clf is not None:\n",
    "    # Remove possible NaN labels\n",
    "    mask = y_clf.notnull() & X_imputed.index.isin(y_clf.index)\n",
    "    Xc = X_imputed.loc[mask]\n",
    "    yc = y_clf.loc[mask]\n",
    "\n",
    "    # Encode labels and split\n",
    "    le = LabelEncoder()\n",
    "    y_enc = le.fit_transform(yc.astype(str))\n",
    "    X_train, X_test, X_train_s, X_test_s, y_train, y_test, scaler_clf = make_split_and_scale(Xc, y_enc)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    clf.fit(X_train_s, y_train)\n",
    "    y_pred = clf.predict(X_test_s)\n",
    "\n",
    "    # Metrics and report\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(le.classes_))\n",
    "    plt.xticks(tick_marks, le.classes_, rotation=45)\n",
    "    plt.yticks(tick_marks, le.classes_)\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, cm[i,j], ha=\"center\", va=\"center\", color=\"black\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"plots/confusion_matrix_clf.png\", dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "    # Feature importances\n",
    "    fi_clf = pd.Series(clf.feature_importances_, index=Xc.columns).sort_values(ascending=False)\n",
    "    display(fi_clf)\n",
    "\n",
    "    # Save classifier & scaler\n",
    "    joblib.dump(clf, \"models/rfc_risk_level.joblib\")\n",
    "    joblib.dump(scaler_clf, \"models/scaler_clf.joblib\")\n",
    "    print(\"Saved RandomForestClassifier and scaler in /models.\")\n",
    "else:\n",
    "    print(\"No categorical 'risk_level' target found — skipping classification.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efd068f0-8ab6-4e42-83de-c529435c082e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No latitude/longitude columns detected for geo-scatter.\n"
     ]
    }
   ],
   "source": [
    "# Quick geo-plot: scatter latitude/longitude color by risk_score (if lat/lon exist)\n",
    "if ('latitude' in X_imputed.columns or 'lat' in X_imputed.columns) and ('longitude' in X_imputed.columns or 'lon' in X_imputed.columns):\n",
    "    # choose exact column names from features if present\n",
    "    lat_col = find_col(df, ['latitude','lat']) or None\n",
    "    lon_col = find_col(df, ['longitude','lon']) or None\n",
    "\n",
    "    if lat_col and lon_col and 'risk_score' in df.columns:\n",
    "        plt.figure(figsize=(8,4))\n",
    "        sc = plt.scatter(df[lon_col], df[lat_col], c=df['risk_score'], s=20, cmap='viridis', alpha=0.7)\n",
    "        plt.colorbar(sc, label='risk_score')\n",
    "        plt.xlabel('longitude'); plt.ylabel('latitude'); plt.title('Geo Scatter colored by risk_score')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"plots/geo_scatter_risk_score.png\", dpi=150)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Latitude/Longitude exist but no 'risk_score' to color by (or columns not detected).\")\n",
    "else:\n",
    "    print(\"No latitude/longitude columns detected for geo-scatter.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b9ecb2d-3f46-4fdd-8075-2d45879c65f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No risk_score or risk_level in dataset. Creating a simple heuristic risk_score (approx).\n",
      "Created heuristic 'risk_score' and 'risk_level' (use only for demo/testing).\n"
     ]
    }
   ],
   "source": [
    "if 'risk_score' not in df.columns and 'risk_level' not in df.columns:\n",
    "    # create a synthetic risk_score using a simple heuristic — only use if you understand it's an approximation\n",
    "    print(\"No risk_score or risk_level in dataset. Creating a simple heuristic risk_score (approx).\")\n",
    "    # heuristic combines available features (if present) — scale each and combine\n",
    "    comb = pd.Series(0, index=df.index, dtype=float)\n",
    "    count = 0\n",
    "    for col in [col_mag, col_fatal, col_econ, col_pop, col_prec, col_temp]:\n",
    "        if col is not None:\n",
    "            s = df[col].astype(float)\n",
    "            # normalize 0-1\n",
    "            s_norm = (s - s.min()) / (s.max() - s.min()) if (s.max() - s.min())!=0 else s*0\n",
    "            comb += s_norm\n",
    "            count += 1\n",
    "    if count>0:\n",
    "        df['risk_score'] = 100 * (comb / count)  # scaled to 0-100\n",
    "        df['risk_level'] = pd.cut(df['risk_score'], bins=[-np.inf,33,66,np.inf], labels=['Low','Medium','High'])\n",
    "        print(\"Created heuristic 'risk_score' and 'risk_level' (use only for demo/testing).\")\n",
    "    else:\n",
    "        print(\"Not enough numeric features to create heuristic risk_score. Please provide a risk column or appropriate features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74922a9c-d0a8-404b-86fb-74e50ce0891c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
